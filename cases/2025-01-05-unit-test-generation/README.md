# 案例：CCG 架构实测 - 单元测试批量生成

**日期**: 2025-01-05

---

## 任务需求（脱敏）

### 项目背景
为某后端项目（Python/FastAPI 技术栈）的核心模块建立完整单元测试覆盖。

### 任务范围

| 阶段 | 目标模块 |
|------|----------|
| 第1阶段 | config.py, processor.py, utils.py, jobs/state.py |
| 第2阶段 | jobs/detect.py, semantic_service_v2.py, API 路由 |
| 第3阶段 | autoexcel 服务层, license_analysis |
| 第4阶段 | 补充测试与覆盖率优化 |

### 测试编写规范要求
- 使用 pytest 框架
- 覆盖正常路径、边界条件、错误处理
- Mock 所有外部依赖（大模型、文件系统、网络）
- 严格禁止修改生产代码

---

## 执行成果

### 代码生成统计

| 类别 | 文件数 | 行数 | 测试用例 |
|------|--------|------|----------|
| **测试代码** | 13 | 7,488 | 481 |
| **配置文件** | 1 | 15 | - |
| **总计** | 14 | 7,503 | 481 |

### 测试覆盖情况

| 模块 | 覆盖率 |
|------|--------|
| config.py | 100% |
| processor.py | 96% |
| jobs/detect.py | 100% |
| jobs/state.py | 100% |

---

## API 价格参考

| 模型 | 输入 (百万 tokens) | 输出 (百万 tokens) |
|------|-------------------|-------------------|
| **Claude Opus 4.5** | $5.00 | $25.00 |
| **GLM 4.7** | $0.60 | $2.20 |

> 价格来源：官方发布信息（2025年）

---

## Token 使用分析

### 直接使用 Claude Opus 4.5 估算

| 消耗类型 | 输入 tokens | 输出 tokens |
|----------|------------|-------------|
| 输出测试代码 | ~30,000 | ~45,000 |
| 调试/修复迭代 | ~40,000 | ~60,000 |
| 读取源文件上下文 | ~30,000 | - |
| **总计** | **~100,000** | **~105,000** |

**估算成本**: $100k × $5/M + $105k × $25/M = **$3.13**

### 使用 CCG 架构实际消耗

| 角色 | 输入 tokens | 输出 tokens | 说明 |
|------|------------|-------------|------|
| **Claude (Opus 4.5)** | | | |
| 读取源文件上下文 | ~8,000 | - | 理解待测模块 |
| 读取 Coder 返回结果 | ~15,000 | - | 验收生成的代码 |
| 输出 prompt 指令 | - | ~5,000 | 分发给 Coder 的任务指令 |
| 验收反馈 | - | ~2,000 | 简短调整意见 |
| **小计** | **~23,000** | **~7,000** | **以输入为主** |
| | | | |
| **Coder (GLM 4.7)** | | | |
| 接收任务指令 + 源文件 | ~45,000 | - | Claude 分发的任务 |
| 输出测试代码 | - | ~105,000 | 大量代码生成 |
| **小计** | **~45,000** | **~105,000** | **以输出为主** |

**实际成本**:
- Opus 4.5: $23k × $5/M + $7k × $25/M = **$0.29**
- GLM 4.7: $45k × $0.60/M + $105k × $2.20/M = **$0.26**
- **总计**: **$0.55**

---

## 成本对比分析

```
┌────────────────────────────────────────────────────────────────────┐
│                      CCG 架构成本节省分析                           │
├────────────────────────────────────────────────────────────────────┤
│  方案              输入        输出        成本      节省率        │
│  ─────────────────────────────────────────────────────────────────  │
│  纯 Opus 4.5       100k        105k        $3.13      -           │
│  CCG (Opus+GLM)    68k         112k        $0.55      82%         │
├────────────────────────────────────────────────────────────────────┤
│  Opus 4.5 Token 节省:     85% (从 205k 降至 30k)                   │
│  Opus 4.5 成本节省:       91% ($3.13 → $0.29)                      │
│  总成本节省:              82% ($3.13 → $0.55)                      │
└────────────────────────────────────────────────────────────────────┘
```

### 关键数据

| 指标 | 数值 |
|------|------|
| 生成测试用例 | **481 个** |
| 生成代码行数 | **7,488 行** |
| Opus token 节省率 | **~85%** |
| Opus 成本节省率 | **~91%** |
| 总成本节省率 | **~82%** |
| 平均每 1000 行成本 | **$0.07** |

### 核心洞察

**Claude (Opus) 不再输出昂贵的代码 token**

在 CCG 模式下，Claude 的 token 消耗模式发生根本变化：
- **输出 token 大幅减少**：从 ~105k（代码生成）降至 ~7k（指令/反馈）
- **输入 token 成为主流**：验收读取结果占比更高
- **成本结构优化**：利用 Opus 便宜的输入价格 ($5/M) vs 昂贵的输出价格 ($25/M)

---

## 工作分配示意

```
Claude (Opus 4.5)              Coder (GLM 4.7)
    │                              │
    ├── 任务拆分规划               │
    ├── 输出 prompt 指令 ────────► 接收任务 + 源文件
    ├── 验收检查 ◄──────────────── 输出测试代码
    ├── 调整下一轮 prompt ───────► (重复 11 次迭代)
    ├── 进度追踪更新               │
    └── 完成判定                   │
```

**迭代模式**: 11 次调用 = 11 轮"验收 → 调整 prompt → 调用 Coder"循环

---

## 结论

本次实测验证了 CCG 架构的核心价值：

1. **成本优化显著**: 在生成 7,488 行测试代码的场景下，总成本从纯 Opus 的 $3.13 降至 $0.55，节省 **82%**

2. **Opus 成本大幅节约**: 高成本模型成本从 $3.13 降至 $0.29，节省 **91%**

3. **关键在于输出 token 转移**: Claude 不再输出昂贵的代码（~105k tokens），只输出简短指令（~7k tokens），利用 Opus 便宜的输入价格处理验收工作

4. **质量不受影响**: 481 个测试用例全部通过，核心模块覆盖率达到 96%-100%

5. **工作模式**: 通过 11 轮"验收 → 调整 prompt → 调用 Coder"迭代，Claude 专注于架构决策和质量把关，Coder 负责大量代码输出

6. **上下文管理优势**: 在整个长任务链中，Claude 甚至没有出现上下文压缩的情况。由于不承担大量代码输出，Claude 的上下文保持干净精简，能够始终保持对任务的全局管理和指导能力。这是纯 Opus 模式下难以实现的——当 Claude 需要亲自输出所有代码时，上下文膨胀会压缩早期信息，导致任务连贯性下降

### 适用场景

此模式适用于：
- 批量代码生成（测试代码、配置文件、样板代码）
- 重复性任务（多个模块的相似处理）
- 清晰规范的任务（有明确输入输出要求）
- 可验证的结果（测试通过/失败、覆盖率等量化指标）
